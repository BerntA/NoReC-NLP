{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis using a Recurrent Neural Network with Long Short Term memory nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Run these if you cannot import the nltk libs.\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__ # Install tensorflow-gpu==2.0.0, if it can utilize CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and create labels based on rating\n",
    "0=negative\n",
    "1=neutral\n",
    "2=positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('data/data.csv', encoding='utf-8')\n",
    "reviews['sentiment'] = [(2 if rating > 3 else 1 if rating == 3 else 0) for rating in reviews.rating]\n",
    "reviews['sentiment_binary'] = [(1 if rating > 3 else 0) for rating in reviews.rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>cons</th>\n",
       "      <th>language</th>\n",
       "      <th>pros</th>\n",
       "      <th>rating</th>\n",
       "      <th>source</th>\n",
       "      <th>source-category</th>\n",
       "      <th>source-tags</th>\n",
       "      <th>split</th>\n",
       "      <th>tags</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>screen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>p3</td>\n",
       "      <td>tv</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>['tv']</td>\n",
       "      <td>rom s topp inn tvdram akkurat andr sist sesong...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>screen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>p3</td>\n",
       "      <td>tv</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>['tv']</td>\n",
       "      <td>twin peaks definitiv gold box edition gull twi...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>screen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>p3</td>\n",
       "      <td>tv</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>['tv']</td>\n",
       "      <td>the wir sesong the wir gjør avheng god måt nes...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>screen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>p3</td>\n",
       "      <td>tv</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>['tv']</td>\n",
       "      <td>mad sesong stil underhold sofistiker tvseri ma...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>screen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>p3</td>\n",
       "      <td>film</td>\n",
       "      <td>[]</td>\n",
       "      <td>train</td>\n",
       "      <td>['movie']</td>\n",
       "      <td>mad sesong tvunderholdning høyest kvalit først...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category cons language pros  rating source source-category source-tags  \\\n",
       "0   screen  NaN       nb  NaN       6     p3              tv          []   \n",
       "1   screen  NaN       nb  NaN       6     p3              tv          []   \n",
       "2   screen  NaN       nb  NaN       6     p3              tv          []   \n",
       "3   screen  NaN       nb  NaN       5     p3              tv          []   \n",
       "4   screen  NaN       nb  NaN       5     p3            film          []   \n",
       "\n",
       "   split       tags                                            content  \\\n",
       "0  train     ['tv']  rom s topp inn tvdram akkurat andr sist sesong...   \n",
       "1  train     ['tv']  twin peaks definitiv gold box edition gull twi...   \n",
       "2  train     ['tv']  the wir sesong the wir gjør avheng god måt nes...   \n",
       "3  train     ['tv']  mad sesong stil underhold sofistiker tvseri ma...   \n",
       "4  train  ['movie']  mad sesong tvunderholdning høyest kvalit først...   \n",
       "\n",
       "   sentiment  sentiment_binary  \n",
       "0          2                 1  \n",
       "1          2                 1  \n",
       "2          2                 1  \n",
       "3          2                 1  \n",
       "4          2                 1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to integer sequence, split into test & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 25000 # Vocabulary size to consider. (common words)\n",
    "max_len = 256 # (230) Computed using the avg amount of words -> (int(np.ceil(np.mean([len(r.split()) for r in reviews.content]))))\n",
    "# currently there are 368281 unique words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_freq = [k for k, _ in Counter(' '.join(reviews.content).split()).most_common(num_words-1)]\n",
    "word_to_freq = {word:(i+1) for i, word in enumerate(word_to_freq)}\n",
    "freq_to_word = {v:k for k,v in word_to_freq.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = np.array([[word_to_freq[word] if word in word_to_freq else 0 for word in r.split()] for r in reviews.content]) # Make representation based on frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stikk',\n",
       " 'kjøp',\n",
       " 'sesong',\n",
       " 'nem',\n",
       " 'verd',\n",
       " 'best',\n",
       " 'tvseri',\n",
       " 'sett',\n",
       " 'fir',\n",
       " 'først']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[freq_to_word[n] if n in freq_to_word else '<OOV>' for n in contents[0]][20:30] # Convert back to words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into test & train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, content, binary=True):\n",
    "    \"\"\"\n",
    "    Split into train vs test & dev\n",
    "    \"\"\"\n",
    "    idxTrain = [i for i,s in zip(df.index, df.split) if s == 'train']\n",
    "    idxTestDev = [i for i,s in zip(df.index, df.split) if s != 'train']    \n",
    "    return content[idxTrain], content[idxTestDev], np.array(df.iloc[idxTrain].sentiment_binary if binary else df.iloc[idxTrain].sentiment), np.array(df.iloc[idxTestDev].sentiment_binary if binary else df.iloc[idxTestDev].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(reviews, contents, False)\n",
    "trainX_b, testX_b, trainY_b, testY_b = train_test_split(reviews, contents, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34903 --- 8711\n"
     ]
    }
   ],
   "source": [
    "print(len(trainY), '---', len(testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train using multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = tf.keras.preprocessing.sequence.pad_sequences(trainX, maxlen=max_len)\n",
    "testX = tf.keras.preprocessing.sequence.pad_sequences(testX, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 256, 100)          2500000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 25)                12600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 78        \n",
      "=================================================================\n",
      "Total params: 2,512,678\n",
      "Trainable params: 2,512,678\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(num_words, 100, input_shape=(trainX.shape[1],)))\n",
    "model.add(tf.keras.layers.LSTM(units=25, activation='tanh', dropout=0.2))\n",
    "model.add(tf.keras.layers.Dense(units=3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30529 samples\n",
      "Epoch 1/5\n",
      "30529/30529 [==============================] - 29s 934us/sample - loss: 0.6119 - accuracy: 0.7593\n",
      "Epoch 2/5\n",
      "30529/30529 [==============================] - 27s 884us/sample - loss: 0.4956 - accuracy: 0.7956\n",
      "Epoch 3/5\n",
      "30529/30529 [==============================] - 26s 862us/sample - loss: 0.4421 - accuracy: 0.8187\n",
      "Epoch 4/5\n",
      "30529/30529 [==============================] - 28s 933us/sample - loss: 0.3948 - accuracy: 0.8437\n",
      "Epoch 5/5\n",
      "30529/30529 [==============================] - 27s 895us/sample - loss: 0.3484 - accuracy: 0.8648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xeebda8b48>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5091904757266105 0.8011463\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(testX, testY, verbose=0)\n",
    "print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train using binary sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_b = tf.keras.preprocessing.sequence.pad_sequences(trainX_b, maxlen=max_len)\n",
    "testX_b = tf.keras.preprocessing.sequence.pad_sequences(testX_b, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 256, 100)          2500000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,580,501\n",
      "Trainable params: 2,580,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(num_words, 100, input_shape=(trainX_b.shape[1],)))\n",
    "model.add(tf.keras.layers.LSTM(units=100, activation='tanh', dropout=0.2))\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(trainX_b, trainY_b, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45621206589586916 0.8411158\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(testX_b, testY_b, verbose=0)\n",
    "print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running predictions on new reveiws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_stemmer = SnowballStemmer(\"norwegian\", ignore_stopwords=False)\n",
    "excludedStopWords = set(['ikkje', 'ikke', 'inkje'])\n",
    "stopWords = set([word for word in set(stopwords.words('norwegian')) if word not in excludedStopWords])\n",
    "def predictReview(text, mdl):\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r'[^a-zæøåéäö ]+', '', text) # Remove any symbols\n",
    "    text = re.sub(r'\\s\\s+', ' ', text) # Remove consequent whitespace    \n",
    "    text = ' '.join([word_stemmer.stem(word) for word in word_tokenize(text) if word not in stopWords])\n",
    "    encoded = np.array([[word_to_freq[word] if word in word_to_freq else 0 for word in text.split()]])\n",
    "    return int(mdl.predict_classes(tf.keras.preprocessing.sequence.pad_sequences(encoded, maxlen=max_len))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews = [\n",
    "    'dÅrlig film! får lyst til å spy!',\n",
    "    'ikke dårlig!',\n",
    "    'den trenger litt finpuss men ellers helt fin',\n",
    "    'den falt ikke i min smak, håper på at sesong 3 blir bedre',\n",
    "    'det kan ikke bli værre musikk en dette her',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[predictReview(review, model) for review in test_reviews] # TODO, review 2 context is not considered?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC, AUC Plot for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = model.predict_classes(testX_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr,tpr,_ = roc_curve(testY_b, predicted_labels)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "plt.plot(fpr,tpr,label='area = %.3f' %roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./img/auc_rnn_binary_lstm', transparent=False, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run with multiple params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_OPTIMIZER = ['adam', 'rmsprop']\n",
    "HP_NUM_UNITS = [25, 50, 100]\n",
    "HP_BATCH_SIZE = [64, 128, 256]\n",
    "HP_DROPOUT = [0, 0.1, 0.2]\n",
    "HP_LEARNING_RATE = [0.001, 0.003, 0.01, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = ['Acc', 'Loss', 'Opt', 'Batch', 'Units', 'Dropout', 'LearnRate']\n",
    "\n",
    "def getOptimizer(opt, rate):\n",
    "    return (tf.keras.optimizers.Adam(learning_rate=rate) if opt == 'adam' else tf.keras.optimizers.RMSprop(learning_rate=rate))\n",
    "\n",
    "def run_model_complex(train_x, train_y, test_x, test_y, vocabulary, binary=False, embedding_size=100, verbose=True):\n",
    "    K.clear_session()\n",
    "    numIter = 1\n",
    "    results = []\n",
    "    \n",
    "    for opt in HP_OPTIMIZER:\n",
    "        for batch in HP_BATCH_SIZE:\n",
    "            for unit in HP_NUM_UNITS:\n",
    "                for dropout in HP_DROPOUT:\n",
    "                    for learn_rate in HP_LEARNING_RATE:\n",
    "                        model = tf.keras.Sequential()\n",
    "                        model.add(tf.keras.layers.Embedding(vocabulary, embedding_size, input_shape=(train_x.shape[1],)))\n",
    "                        model.add(tf.keras.layers.LSTM(units=unit, activation='tanh', dropout=dropout))\n",
    "                        model.add(tf.keras.layers.Dense(units=1 if binary else 3, activation='sigmoid' if binary else 'softmax'))\n",
    "                        model.compile(optimizer=getOptimizer(opt, learn_rate), loss='binary_crossentropy' if binary else 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "                        model.fit(train_x, train_y, epochs=3, batch_size=batch, verbose=0)\n",
    "                        loss, accuracy = model.evaluate(test_x, test_y, verbose=0)                        \n",
    "                        results.append([accuracy, loss, opt, batch, unit, dropout, learn_rate])\n",
    "                        if verbose and ((numIter % 4) == 0):\n",
    "                            print(numIter, \"Processed ---> {:.3f} LOSS, {:.3f} ACCU\".format(loss, accuracy))\n",
    "                        numIter += 1\n",
    "                        K.clear_session()\n",
    "                        model = None\n",
    "                            \n",
    "    results.sort(key = lambda x: x[1]) # Sort on LOSS, low->high\n",
    "    return results\n",
    "\n",
    "def createDataFrameForResults(res):\n",
    "    data = np.array(res)\n",
    "    df = pd.DataFrame()\n",
    "    for i, c in enumerate(COLUMNS):\n",
    "        df[c] = data[:,i]    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res1 = run_model_complex(trainX, trainY, testX, testY, num_words) # Takes approx 4hr and 20min avg 1.2 min per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res2 = run_model_complex(trainX_b, trainY_b, testX_b, testY_b, num_words, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = createDataFrameForResults(res1)\n",
    "#df1.to_csv ('./params/rnn_multi_params.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = createDataFrameForResults(res2)\n",
    "#df2.to_csv ('./params/rnn_binary_params.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load result params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7981,0.522,rmsprop,64,100,0.0,0.003\n",
      "0.7979,0.612,rmsprop,64,50,0.1,0.003\n",
      "0.7957,0.617,rmsprop,64,25,0.2,0.01\n",
      "0.795,0.5395,rmsprop,64,50,0.2,0.001\n",
      "0.7943,0.544,rmsprop,64,100,0.2,0.01\n",
      "0.7937,0.5354,rmsprop,64,100,0.1,0.003\n",
      "0.7924,0.5842,rmsprop,128,100,0.2,0.01\n",
      "0.792,0.5382,rmsprop,64,25,0.0,0.003\n",
      "0.792,0.5994,rmsprop,64,25,0.0,0.01\n",
      "0.7915,0.5528,rmsprop,64,100,0.1,0.01\n",
      "0.7912,0.5381,rmsprop,128,50,0.2,0.001\n",
      "0.7911,0.518,rmsprop,64,100,0.1,0.001\n",
      "0.7908,0.5127,rmsprop,64,25,0.2,0.001\n",
      "0.7895,0.5503,rmsprop,64,50,0.1,0.01\n",
      "0.7894,0.583,rmsprop,128,100,0.1,0.01\n",
      "0.789,0.5228,rmsprop,64,25,0.2,0.003\n",
      "0.7888,0.5952,rmsprop,128,25,0.2,0.01\n",
      "0.7888,0.5439,rmsprop,128,100,0.1,0.001\n",
      "0.7885,0.5629,rmsprop,128,100,0.2,0.003\n",
      "0.7883,0.6587,rmsprop,64,50,0.0,0.01\n",
      "0.7879,0.5326,rmsprop,128,50,0.0,0.001\n",
      "0.7877,0.5765,rmsprop,64,50,0.0,0.003\n",
      "0.7874,0.6283,rmsprop,256,50,0.0,0.001\n",
      "0.7871,0.5331,rmsprop,64,100,0.0,0.001\n",
      "0.7864,0.6251,rmsprop,256,100,0.2,0.01\n",
      "0.7864,0.6793,adam,128,100,0.2,0.01\n",
      "0.7861,0.5743,rmsprop,64,50,0.2,0.01\n",
      "0.7859,0.6169,rmsprop,128,50,0.1,0.01\n",
      "0.7853,0.5317,rmsprop,256,50,0.1,0.001\n",
      "0.7853,0.5725,rmsprop,64,100,0.0,0.01\n",
      "0.785,0.5417,rmsprop,128,25,0.1,0.001\n",
      "0.785,0.6213,rmsprop,128,25,0.1,0.01\n",
      "0.7848,0.637,adam,64,50,0.0,0.001\n",
      "0.784,0.6292,adam,128,100,0.0,0.001\n",
      "0.7836,0.5511,rmsprop,64,25,0.1,0.003\n",
      "0.7836,0.5707,rmsprop,128,50,0.2,0.003\n",
      "0.7835,0.6527,rmsprop,256,25,0.1,0.01\n",
      "0.7832,0.6006,adam,128,50,0.0,0.001\n",
      "0.783,0.5429,rmsprop,128,25,0.2,0.001\n",
      "0.7826,0.5804,adam,256,50,0.2,0.001\n",
      "0.7825,0.6348,adam,64,50,0.1,0.001\n",
      "0.7823,0.5346,rmsprop,64,50,0.1,0.001\n",
      "0.7816,0.546,rmsprop,128,100,0.0,0.003\n",
      "0.7814,0.5736,adam,256,100,0.0,0.001\n",
      "0.7808,0.5998,rmsprop,128,25,0.1,0.003\n",
      "0.7804,0.5395,rmsprop,128,25,0.0,0.001\n",
      "0.7804,0.6007,rmsprop,64,100,0.2,0.003\n",
      "0.7802,0.6174,rmsprop,64,25,0.0,0.001\n",
      "0.7801,0.553,rmsprop,128,50,0.2,0.01\n",
      "0.7801,0.7441,adam,128,25,0.2,0.01\n",
      "0.7797,0.5565,rmsprop,256,100,0.0,0.001\n",
      "0.7796,0.5888,adam,64,50,0.2,0.001\n",
      "0.7794,0.5991,rmsprop,256,25,0.2,0.01\n",
      "0.7792,0.6415,rmsprop,256,50,0.0,0.01\n",
      "0.779,0.5947,adam,128,50,0.1,0.001\n",
      "0.7789,0.5549,rmsprop,128,50,0.1,0.003\n",
      "0.7789,0.5684,adam,128,25,0.2,0.001\n",
      "0.7788,0.6092,rmsprop,256,25,0.2,0.001\n",
      "0.7787,0.6829,adam,64,50,0.0,0.01\n",
      "0.7786,0.6575,adam,128,25,0.1,0.003\n",
      "0.7781,0.7492,adam,256,25,0.1,0.01\n",
      "0.7781,0.6202,adam,64,100,0.1,0.001\n",
      "0.7778,0.5955,rmsprop,64,25,0.1,0.01\n",
      "0.7777,0.5905,adam,128,50,0.2,0.001\n",
      "0.7774,0.5976,adam,128,100,0.1,0.001\n",
      "0.7774,0.7421,adam,256,100,0.0,0.01\n",
      "0.7772,0.6571,adam,64,50,0.1,0.01\n",
      "0.777,0.6777,adam,128,50,0.0,0.003\n",
      "0.7767,0.5755,adam,256,50,0.0,0.001\n",
      "0.7765,0.6452,adam,64,50,0.2,0.003\n",
      "0.7764,0.5821,adam,256,50,0.1,0.001\n",
      "0.7763,0.564,rmsprop,256,50,0.2,0.001\n",
      "0.7762,0.5254,rmsprop,128,50,0.1,0.001\n",
      "0.7762,0.5717,rmsprop,128,25,0.0,0.01\n",
      "0.7762,0.5882,adam,256,25,0.1,0.001\n",
      "0.7761,0.6588,adam,64,25,0.2,0.003\n",
      "0.7759,0.6462,rmsprop,128,50,0.0,0.01\n",
      "0.7756,0.6775,adam,64,100,0.0,0.003\n",
      "0.7755,0.7102,adam,256,50,0.1,0.01\n",
      "0.7747,0.5775,adam,256,25,0.0,0.001\n",
      "0.7747,0.5798,rmsprop,256,25,0.1,0.003\n",
      "0.7745,0.5506,rmsprop,256,25,0.1,0.001\n",
      "0.7743,0.5452,rmsprop,128,25,0.2,0.003\n",
      "0.7742,0.694,adam,128,100,0.0,0.01\n",
      "0.7742,0.7179,adam,128,50,0.1,0.01\n",
      "0.7741,0.6717,adam,128,100,0.1,0.01\n",
      "0.7741,0.6853,adam,128,100,0.0,0.003\n",
      "0.774,0.7084,rmsprop,64,100,0.2,0.001\n",
      "0.7737,0.6113,adam,64,100,0.0,0.001\n",
      "0.7733,0.6599,adam,256,50,0.2,0.003\n",
      "0.773,0.6322,adam,128,100,0.1,0.003\n",
      "0.7728,0.5235,rmsprop,64,50,0.2,0.003\n",
      "0.7726,0.5876,adam,256,100,0.1,0.001\n",
      "0.772,0.6179,adam,64,100,0.2,0.001\n",
      "0.772,0.7507,adam,128,25,0.0,0.01\n",
      "0.7719,0.6874,adam,64,25,0.0,0.003\n",
      "0.7716,0.5956,rmsprop,256,50,0.1,0.003\n",
      "0.7716,0.6294,adam,64,100,0.1,0.01\n",
      "0.7711,0.5411,rmsprop,256,25,0.0,0.001\n",
      "0.7711,0.6294,adam,64,25,0.1,0.001\n",
      "0.7707,0.6446,adam,256,100,0.1,0.003\n",
      "0.7704,0.688,adam,256,100,0.2,0.01\n",
      "0.7701,0.6711,adam,128,25,0.1,0.01\n",
      "0.7694,0.6495,adam,64,25,0.2,0.01\n",
      "0.769,0.5917,rmsprop,128,100,0.0,0.01\n",
      "0.7689,0.593,adam,256,25,0.2,0.001\n",
      "0.7689,0.6747,adam,256,50,0.0,0.01\n",
      "0.7687,0.6038,rmsprop,256,100,0.0,0.003\n",
      "0.7681,0.5619,rmsprop,256,100,0.1,0.001\n",
      "0.7681,0.6632,adam,128,50,0.2,0.003\n",
      "0.768,0.6857,adam,256,25,0.0,0.01\n",
      "0.7679,0.5847,adam,128,25,0.1,0.001\n",
      "0.7677,0.6593,adam,256,25,0.2,0.01\n",
      "0.7676,0.6515,adam,128,25,0.2,0.003\n",
      "0.7672,0.6157,adam,256,25,0.1,0.003\n",
      "0.767,0.5861,rmsprop,256,100,0.2,0.003\n",
      "0.7668,0.6199,rmsprop,128,50,0.0,0.003\n",
      "0.7666,0.7837,rmsprop,64,25,0.1,0.001\n",
      "0.7655,0.6794,adam,256,50,0.2,0.01\n",
      "0.7655,0.6997,adam,256,50,0.0,0.003\n",
      "0.7651,0.6554,adam,64,100,0.1,0.003\n",
      "0.765,0.6565,adam,128,25,0.0,0.003\n",
      "0.7648,0.6125,adam,64,25,0.0,0.001\n",
      "0.7643,0.5568,rmsprop,256,25,0.2,0.003\n",
      "0.7643,0.5823,rmsprop,256,100,0.1,0.003\n",
      "0.7642,0.554,rmsprop,256,100,0.2,0.001\n",
      "0.7639,0.6605,adam,64,25,0.1,0.01\n",
      "0.7636,0.6668,adam,128,50,0.2,0.01\n",
      "0.7634,0.6509,adam,64,50,0.2,0.01\n",
      "0.7626,0.5673,adam,256,100,0.2,0.001\n",
      "0.7625,0.6374,adam,128,100,0.2,0.003\n",
      "0.7622,0.6585,adam,64,25,0.1,0.003\n",
      "0.7587,0.6306,adam,64,100,0.0,0.01\n",
      "0.7584,0.5865,adam,128,25,0.0,0.001\n",
      "0.7577,0.6124,adam,256,100,0.2,0.003\n",
      "0.7571,0.6029,adam,64,25,0.2,0.001\n",
      "0.7556,0.6435,adam,64,25,0.0,0.01\n",
      "0.7555,0.6466,adam,128,50,0.1,0.003\n",
      "0.7552,0.6591,adam,256,100,0.1,0.01\n",
      "0.7552,0.6945,adam,64,50,0.0,0.003\n",
      "0.7541,0.5583,rmsprop,128,100,0.0,0.001\n",
      "0.7535,0.6432,adam,64,100,0.2,0.003\n",
      "0.7535,0.5803,rmsprop,256,100,0.1,0.01\n",
      "0.7525,0.6833,adam,64,100,0.2,0.01\n",
      "0.7517,0.5641,rmsprop,128,100,0.2,0.001\n",
      "0.7516,0.6138,rmsprop,256,50,0.2,0.01\n",
      "0.7515,0.6447,adam,256,25,0.0,0.003\n",
      "0.7513,0.5919,adam,128,100,0.2,0.001\n",
      "0.7507,0.7314,adam,128,25,0.2,0.1\n",
      "0.7506,0.76,adam,128,50,0.0,0.1\n",
      "0.7501,0.8561,rmsprop,64,25,0.0,0.1\n",
      "0.7499,0.7283,adam,256,25,0.0,0.1\n",
      "0.7496,0.7344,adam,128,25,0.1,0.1\n",
      "0.7494,0.6831,adam,128,50,0.0,0.01\n",
      "0.749,0.8184,rmsprop,64,50,0.1,0.1\n",
      "0.7484,0.6553,rmsprop,256,100,0.0,0.01\n",
      "0.7484,0.7749,adam,128,25,0.0,0.1\n",
      "0.7476,0.7258,adam,256,25,0.1,0.1\n",
      "0.7476,0.6802,adam,64,50,0.1,0.003\n",
      "0.7473,0.5796,rmsprop,128,100,0.1,0.003\n",
      "0.7471,0.802,rmsprop,256,50,0.1,0.1\n",
      "0.7466,0.7549,rmsprop,256,25,0.2,0.1\n",
      "0.7458,0.7769,adam,128,50,0.2,0.1\n",
      "0.7457,0.7493,adam,256,50,0.0,0.1\n",
      "0.7454,0.9545,adam,64,100,0.0,0.1\n",
      "0.7444,0.6286,adam,256,25,0.2,0.003\n",
      "0.7442,0.8435,rmsprop,64,25,0.2,0.1\n",
      "0.7439,0.7487,adam,128,50,0.1,0.1\n",
      "0.7434,0.735,rmsprop,128,25,0.2,0.1\n",
      "0.7432,0.7287,rmsprop,256,25,0.1,0.1\n",
      "0.7431,0.6669,adam,256,50,0.1,0.003\n",
      "0.7431,0.7524,adam,256,100,0.1,0.1\n",
      "0.7419,0.7734,adam,64,25,0.0,0.1\n",
      "0.7415,0.7399,adam,256,50,0.1,0.1\n",
      "0.7415,0.7822,adam,64,50,0.2,0.1\n",
      "0.7412,0.757,adam,256,100,0.0,0.1\n",
      "0.7408,0.831,rmsprop,64,50,0.2,0.1\n",
      "0.7394,0.7711,rmsprop,128,25,0.1,0.1\n",
      "0.7374,0.7666,rmsprop,256,50,0.2,0.1\n",
      "0.737,0.6444,adam,256,100,0.0,0.003\n",
      "0.7362,0.7513,rmsprop,128,25,0.0,0.1\n",
      "0.7359,0.7859,adam,128,100,0.1,0.1\n",
      "0.7358,0.7346,adam,256,25,0.2,0.1\n",
      "0.735,0.7703,adam,128,100,0.2,0.1\n",
      "0.7349,0.9888,rmsprop,64,100,0.0,0.1\n",
      "0.7347,0.6423,rmsprop,256,50,0.1,0.01\n",
      "0.734,0.7746,adam,64,50,0.0,0.1\n",
      "0.7286,0.6298,rmsprop,256,50,0.2,0.003\n",
      "0.728,0.7763,adam,128,100,0.0,0.1\n",
      "0.7265,0.766,rmsprop,128,50,0.1,0.1\n",
      "0.7265,0.784,rmsprop,128,50,0.2,0.1\n",
      "0.725,0.7999,adam,64,50,0.1,0.1\n",
      "0.7221,0.9473,rmsprop,128,100,0.0,0.1\n",
      "0.7191,0.701,rmsprop,256,25,0.0,0.01\n",
      "0.7166,0.774,adam,64,25,0.2,0.1\n",
      "0.716,0.7449,rmsprop,256,25,0.0,0.1\n",
      "0.7153,0.9362,rmsprop,64,100,0.1,0.1\n",
      "0.7143,0.7794,adam,256,50,0.2,0.1\n",
      "0.7122,0.8106,rmsprop,256,100,0.0,0.1\n",
      "0.711,0.7981,rmsprop,256,50,0.0,0.1\n",
      "0.7075,0.6451,rmsprop,256,25,0.0,0.003\n",
      "0.7061,0.9475,rmsprop,64,100,0.2,0.1\n",
      "0.706,0.6677,rmsprop,128,25,0.0,0.003\n",
      "0.7039,0.7824,rmsprop,128,50,0.0,0.1\n",
      "0.7036,0.8337,rmsprop,64,50,0.0,0.1\n",
      "0.7035,0.797,adam,256,100,0.2,0.1\n",
      "0.6778,0.7232,rmsprop,256,50,0.0,0.003\n",
      "0.665,0.8094,adam,64,25,0.1,0.1\n",
      "0.6641,0.9356,adam,64,100,0.1,0.1\n",
      "0.6519,0.9138,rmsprop,128,100,0.2,0.1\n",
      "0.6212,0.8806,rmsprop,256,100,0.1,0.1\n",
      "0.6164,0.9286,rmsprop,128,100,0.1,0.1\n",
      "0.5696,1.231,adam,64,100,0.2,0.1\n",
      "0.5191,0.8943,rmsprop,64,50,0.0,0.001\n",
      "0.4316,1.118,rmsprop,64,25,0.1,0.1\n",
      "0.3989,1.673,rmsprop,256,100,0.2,0.1\n"
     ]
    }
   ],
   "source": [
    "for obj in sorted(pd.read_csv('./params/rnn_multi_params.csv', names=COLUMNS).values.tolist(), key=lambda x:x[0], reverse=True):\n",
    "    print(\"{:.4},{:.4},{},{},{},{},{}\".format(obj[0], obj[1], obj[2], obj[3], obj[4], obj[5], obj[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8513,0.4058,rmsprop,64,100,0.1,0.003\n",
      "0.8488,0.3615,rmsprop,64,100,0.2,0.001\n",
      "0.8484,0.3901,rmsprop,64,50,0.2,0.001\n",
      "0.8471,0.3911,rmsprop,64,50,0.2,0.003\n",
      "0.8459,0.3625,rmsprop,128,100,0.2,0.01\n",
      "0.8455,0.4079,rmsprop,128,50,0.2,0.01\n",
      "0.8449,0.3873,rmsprop,64,25,0.1,0.003\n",
      "0.8446,0.4043,rmsprop,64,100,0.1,0.01\n",
      "0.8445,0.3934,rmsprop,64,50,0.1,0.01\n",
      "0.8445,0.4042,rmsprop,128,50,0.2,0.001\n",
      "0.8442,0.4353,rmsprop,64,50,0.0,0.01\n",
      "0.843,0.4505,rmsprop,64,100,0.2,0.003\n",
      "0.8426,0.3887,rmsprop,128,50,0.0,0.001\n",
      "0.8424,0.3795,rmsprop,128,100,0.0,0.003\n",
      "0.8422,0.5058,rmsprop,64,50,0.2,0.01\n",
      "0.8421,0.3676,rmsprop,128,100,0.1,0.003\n",
      "0.842,0.412,rmsprop,128,100,0.0,0.01\n",
      "0.8418,0.3858,rmsprop,64,50,0.0,0.003\n",
      "0.8414,0.3857,rmsprop,128,100,0.1,0.01\n",
      "0.8413,0.3918,rmsprop,128,25,0.2,0.01\n",
      "0.8407,0.3771,rmsprop,128,25,0.2,0.001\n",
      "0.8405,0.4197,rmsprop,256,100,0.1,0.01\n",
      "0.8403,0.3893,rmsprop,64,25,0.1,0.001\n",
      "0.8397,0.4161,rmsprop,128,100,0.0,0.001\n",
      "0.8391,0.4368,rmsprop,128,25,0.1,0.01\n",
      "0.8382,0.4886,rmsprop,64,100,0.2,0.01\n",
      "0.8381,0.4004,rmsprop,128,50,0.0,0.003\n",
      "0.8379,0.4031,rmsprop,64,25,0.2,0.01\n",
      "0.8374,0.3772,rmsprop,128,100,0.2,0.003\n",
      "0.8374,0.4185,rmsprop,128,25,0.1,0.003\n",
      "0.8372,0.3908,rmsprop,64,25,0.2,0.003\n",
      "0.8371,0.411,rmsprop,256,50,0.0,0.001\n",
      "0.8371,0.4285,rmsprop,64,25,0.1,0.01\n",
      "0.8371,0.4449,rmsprop,256,100,0.2,0.01\n",
      "0.8369,0.3777,rmsprop,256,25,0.2,0.001\n",
      "0.8368,0.3808,rmsprop,256,100,0.2,0.001\n",
      "0.8364,0.4397,rmsprop,64,100,0.0,0.01\n",
      "0.8348,0.4346,rmsprop,64,25,0.0,0.003\n",
      "0.8342,0.4014,rmsprop,128,25,0.0,0.01\n",
      "0.834,0.4891,adam,128,25,0.2,0.01\n",
      "0.8339,0.4174,rmsprop,256,50,0.2,0.01\n",
      "0.8339,0.4235,rmsprop,256,25,0.1,0.01\n",
      "0.8339,0.4594,adam,128,100,0.0,0.01\n",
      "0.8337,0.3758,rmsprop,128,25,0.2,0.003\n",
      "0.833,0.454,adam,64,25,0.1,0.001\n",
      "0.8327,0.3928,rmsprop,128,100,0.2,0.001\n",
      "0.8325,0.3896,rmsprop,128,50,0.2,0.003\n",
      "0.8319,0.4364,adam,128,25,0.2,0.001\n",
      "0.8319,0.456,adam,64,50,0.2,0.001\n",
      "0.8313,0.4263,rmsprop,256,25,0.0,0.001\n",
      "0.831,0.3785,rmsprop,128,25,0.0,0.001\n",
      "0.8305,0.4291,adam,256,100,0.2,0.001\n",
      "0.8305,0.4707,adam,128,50,0.0,0.01\n",
      "0.8304,0.4367,rmsprop,256,25,0.0,0.01\n",
      "0.8303,0.3967,rmsprop,256,100,0.1,0.001\n",
      "0.83,0.4289,rmsprop,256,25,0.2,0.01\n",
      "0.8293,0.4195,rmsprop,64,25,0.0,0.001\n",
      "0.8292,0.4723,rmsprop,256,50,0.0,0.01\n",
      "0.8291,0.4632,adam,64,25,0.2,0.001\n",
      "0.8286,0.4183,rmsprop,256,100,0.0,0.01\n",
      "0.8283,0.417,adam,256,50,0.2,0.001\n",
      "0.8281,0.4153,rmsprop,128,50,0.0,0.01\n",
      "0.8281,0.4535,adam,128,25,0.2,0.003\n",
      "0.8276,0.4132,adam,128,50,0.2,0.001\n",
      "0.8274,0.4681,adam,256,100,0.1,0.01\n",
      "0.8269,0.4145,adam,256,50,0.1,0.001\n",
      "0.8269,0.433,rmsprop,256,100,0.0,0.001\n",
      "0.8267,0.5168,adam,128,25,0.0,0.01\n",
      "0.8265,0.449,adam,128,100,0.2,0.001\n",
      "0.8263,0.5318,adam,256,50,0.0,0.01\n",
      "0.8258,0.5113,adam,64,25,0.2,0.003\n",
      "0.8253,0.498,adam,64,25,0.0,0.001\n",
      "0.8251,0.5284,adam,256,50,0.2,0.003\n",
      "0.8247,0.426,adam,256,100,0.1,0.001\n",
      "0.8246,0.4171,adam,256,25,0.1,0.001\n",
      "0.8246,0.453,rmsprop,256,25,0.0,0.003\n",
      "0.8246,0.4576,adam,256,25,0.2,0.003\n",
      "0.8246,0.4832,rmsprop,128,25,0.1,0.001\n",
      "0.8245,0.4687,adam,256,100,0.0,0.01\n",
      "0.8241,0.4605,adam,64,50,0.2,0.01\n",
      "0.8241,0.4505,adam,256,100,0.0,0.003\n",
      "0.824,0.4286,adam,128,50,0.0,0.001\n",
      "0.824,0.4641,adam,128,50,0.1,0.01\n",
      "0.8238,0.4497,adam,128,100,0.1,0.001\n",
      "0.8238,0.4506,adam,128,50,0.2,0.01\n",
      "0.8238,0.4676,adam,128,100,0.0,0.001\n",
      "0.8237,0.411,rmsprop,64,50,0.1,0.001\n",
      "0.8236,0.4865,adam,128,25,0.0,0.003\n",
      "0.8235,0.4138,adam,256,25,0.0,0.001\n",
      "0.8235,0.4694,adam,128,100,0.2,0.003\n",
      "0.8232,0.4375,adam,64,100,0.0,0.01\n",
      "0.8232,0.4239,rmsprop,256,50,0.1,0.01\n",
      "0.8231,0.4648,adam,128,100,0.2,0.01\n",
      "0.8228,0.5076,adam,256,25,0.1,0.01\n",
      "0.8226,0.4184,adam,256,50,0.0,0.001\n",
      "0.8226,0.4727,adam,64,50,0.0,0.01\n",
      "0.8225,0.4288,adam,64,25,0.2,0.01\n",
      "0.8225,0.4466,adam,128,25,0.1,0.001\n",
      "0.8223,0.4354,adam,256,25,0.0,0.01\n",
      "0.8223,0.4621,adam,64,50,0.1,0.01\n",
      "0.8221,0.4584,adam,128,25,0.1,0.003\n",
      "0.8218,0.4568,adam,128,100,0.1,0.01\n",
      "0.8217,0.4277,rmsprop,128,100,0.1,0.001\n",
      "0.8216,0.4566,adam,128,50,0.1,0.001\n",
      "0.8213,0.4719,adam,64,25,0.0,0.01\n",
      "0.8213,0.4841,adam,128,25,0.1,0.01\n",
      "0.8207,0.4296,rmsprop,128,50,0.1,0.01\n",
      "0.8207,0.4298,adam,64,100,0.2,0.01\n",
      "0.8206,0.4965,adam,64,25,0.1,0.003\n",
      "0.8201,0.4442,adam,64,100,0.0,0.003\n",
      "0.8198,0.4079,rmsprop,256,50,0.1,0.003\n",
      "0.8197,0.4715,adam,64,50,0.1,0.001\n",
      "0.8196,0.4363,adam,64,25,0.1,0.01\n",
      "0.819,0.4271,adam,256,100,0.0,0.001\n",
      "0.8183,0.4472,adam,64,50,0.0,0.003\n",
      "0.8181,0.4981,adam,64,25,0.0,0.003\n",
      "0.8174,0.4222,rmsprop,256,100,0.0,0.003\n",
      "0.8173,0.4059,adam,256,25,0.2,0.001\n",
      "0.8173,0.4172,rmsprop,128,50,0.1,0.003\n",
      "0.8172,0.4424,adam,64,50,0.0,0.001\n",
      "0.8167,0.4426,adam,64,100,0.1,0.003\n",
      "0.8164,0.4612,adam,256,25,0.2,0.01\n",
      "0.8158,0.4081,rmsprop,256,25,0.1,0.003\n",
      "0.8156,0.4611,adam,64,100,0.2,0.003\n",
      "0.8155,0.4985,adam,256,25,0.1,0.003\n",
      "0.8151,0.4244,adam,128,25,0.0,0.001\n",
      "0.8147,0.5011,adam,128,50,0.1,0.003\n",
      "0.8146,0.5211,adam,64,50,0.1,0.003\n",
      "0.8145,0.4766,adam,256,50,0.0,0.003\n",
      "0.8144,0.429,rmsprop,64,25,0.0,0.01\n",
      "0.8144,0.399,rmsprop,256,25,0.1,0.001\n",
      "0.8144,0.5251,rmsprop,256,100,0.1,0.003\n",
      "0.8139,0.4429,adam,256,25,0.0,0.003\n",
      "0.8139,0.4525,adam,64,100,0.1,0.001\n",
      "0.8139,0.4754,adam,256,50,0.1,0.003\n",
      "0.8138,0.4687,adam,128,100,0.1,0.003\n",
      "0.8136,0.4453,adam,256,100,0.1,0.003\n",
      "0.8135,0.4723,adam,256,100,0.2,0.01\n",
      "0.8133,0.4353,adam,64,100,0.2,0.001\n",
      "0.8131,0.4453,adam,128,50,0.2,0.003\n",
      "0.813,0.4772,adam,128,50,0.0,0.003\n",
      "0.8125,0.4452,adam,256,50,0.2,0.01\n",
      "0.8119,0.4455,adam,64,100,0.1,0.01\n",
      "0.8116,0.5058,rmsprop,256,50,0.2,0.003\n",
      "0.81,0.455,adam,64,100,0.0,0.001\n",
      "0.8092,0.4552,adam,64,50,0.2,0.003\n",
      "0.8085,0.4531,rmsprop,64,100,0.0,0.001\n",
      "0.8078,0.4714,adam,256,50,0.1,0.01\n",
      "0.8077,0.4387,rmsprop,64,100,0.0,0.003\n",
      "0.8071,0.4056,rmsprop,128,25,0.0,0.003\n",
      "0.807,0.5229,rmsprop,64,25,0.2,0.001\n",
      "0.8062,0.4814,adam,128,100,0.0,0.003\n",
      "0.8041,0.424,rmsprop,256,50,0.0,0.003\n",
      "0.804,0.6075,rmsprop,128,50,0.1,0.001\n",
      "0.8026,0.5194,rmsprop,256,25,0.2,0.003\n",
      "0.8005,0.4788,adam,256,100,0.2,0.003\n",
      "0.7986,0.4303,rmsprop,256,50,0.1,0.001\n",
      "0.7985,0.5724,rmsprop,256,100,0.2,0.003\n",
      "0.7954,0.7378,rmsprop,64,50,0.0,0.001\n",
      "0.7539,0.7171,rmsprop,64,50,0.1,0.003\n",
      "0.7509,0.5732,adam,64,25,0.1,0.1\n",
      "0.7509,0.5727,adam,128,100,0.2,0.1\n",
      "0.7508,nan,rmsprop,256,100,0.1,0.1\n",
      "0.7506,0.5667,adam,128,25,0.1,0.1\n",
      "0.7506,0.6184,adam,128,50,0.1,0.1\n",
      "0.7502,0.6139,rmsprop,128,50,0.0,0.1\n",
      "0.7502,0.6254,rmsprop,64,25,0.0,0.1\n",
      "0.7499,0.6325,rmsprop,64,50,0.0,0.1\n",
      "0.7496,0.6534,rmsprop,64,25,0.1,0.1\n",
      "0.7496,0.7257,rmsprop,64,25,0.2,0.1\n",
      "0.7494,0.5892,rmsprop,128,25,0.2,0.1\n",
      "0.7494,0.665,rmsprop,64,50,0.1,0.1\n",
      "0.7482,0.5836,adam,128,25,0.0,0.1\n",
      "0.7482,0.5912,adam,128,50,0.0,0.1\n",
      "0.7481,0.5748,adam,64,25,0.2,0.1\n",
      "0.7478,0.5635,adam,256,25,0.2,0.1\n",
      "0.7473,0.5742,adam,64,50,0.0,0.1\n",
      "0.7465,0.595,rmsprop,256,25,0.2,0.1\n",
      "0.7462,0.8272,rmsprop,64,100,0.1,0.1\n",
      "0.7461,0.7236,rmsprop,64,100,0.0,0.1\n",
      "0.746,0.6534,adam,64,100,0.2,0.1\n",
      "0.7457,0.5806,rmsprop,256,25,0.0,0.1\n",
      "0.7456,0.6199,rmsprop,64,50,0.2,0.1\n",
      "0.7451,0.5963,adam,64,50,0.1,0.1\n",
      "0.7443,0.5791,adam,256,25,0.0,0.1\n",
      "0.7438,0.6013,adam,128,100,0.1,0.1\n",
      "0.743,0.5844,adam,128,100,0.0,0.1\n",
      "0.7428,0.5746,adam,256,50,0.0,0.1\n",
      "0.7426,0.5735,adam,256,25,0.1,0.1\n",
      "0.7426,0.6425,rmsprop,256,100,0.2,0.1\n",
      "0.7416,0.5975,rmsprop,128,25,0.0,0.1\n",
      "0.7414,0.5658,rmsprop,128,50,0.2,0.1\n",
      "0.7414,0.5746,adam,128,50,0.2,0.1\n",
      "0.7402,0.5735,adam,256,50,0.2,0.1\n",
      "0.7395,0.5971,adam,64,100,0.0,0.1\n",
      "0.7388,0.5831,adam,256,100,0.0,0.1\n",
      "0.7379,0.5642,rmsprop,128,25,0.1,0.1\n",
      "0.7367,0.5738,adam,128,25,0.2,0.1\n",
      "0.7359,0.6238,rmsprop,128,100,0.2,0.1\n",
      "0.7334,0.5776,adam,256,100,0.1,0.1\n",
      "0.7327,0.5716,rmsprop,256,25,0.1,0.1\n",
      "0.7318,0.5329,rmsprop,64,100,0.1,0.001\n",
      "0.728,0.5901,rmsprop,256,50,0.0,0.1\n",
      "0.7277,0.5778,rmsprop,256,50,0.1,0.1\n",
      "0.7255,0.5991,rmsprop,128,50,0.1,0.1\n",
      "0.7239,0.5897,adam,256,50,0.1,0.1\n",
      "0.7217,0.6048,adam,64,25,0.0,0.1\n",
      "0.7169,0.5864,adam,256,100,0.2,0.1\n",
      "0.7169,0.6384,rmsprop,256,50,0.2,0.001\n",
      "0.7144,0.5921,rmsprop,256,100,0.0,0.1\n",
      "0.7068,0.6073,rmsprop,128,100,0.0,0.1\n",
      "0.6976,0.6192,rmsprop,128,100,0.1,0.1\n",
      "0.686,0.6142,rmsprop,256,50,0.2,0.1\n",
      "0.6229,0.8524,adam,64,100,0.1,0.1\n",
      "0.6082,0.6632,adam,64,50,0.2,0.1\n",
      "0.5838,0.9218,rmsprop,64,100,0.2,0.1\n"
     ]
    }
   ],
   "source": [
    "for obj in sorted(pd.read_csv('./params/rnn_binary_params.csv', names=COLUMNS).values.tolist(), key=lambda x:x[0], reverse=True):\n",
    "    print(\"{:.4},{:.4},{},{},{},{},{}\".format(obj[0], obj[1], obj[2], obj[3], obj[4], obj[5], obj[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
